{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaml import load, Loader\n",
    "from bunch import Bunch\n",
    "Bunch.__str__ = Bunch.__repr__\n",
    "\n",
    "stream = open(\"config.yaml\", 'r')\n",
    "config = Bunch(load(stream, Loader=Loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotting_util as putil\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "SIGNAL_COMBOS = [['driver_behavior', 'vehicle_behavior'], ['driver_behavior', 'vehicle_behavior', 'navi'],\n",
    "                ['driver_behavior', 'vehicle_behavior', 'radar'], ['driver_behavior', 'vehicle_behavior', 'navi', 'radar']]\n",
    "\n",
    "metrics = ['test_balanced_accuracy', 'train_balanced_accuracy', 'test_roc_auc', 'train_roc_auc']\n",
    "\n",
    "can_data = pd.read_parquet('out/can_data.parquet', columns=['subject_id'])\n",
    "subject_ids = np.unique(can_data['subject_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare window sizes\n",
    "scores = []\n",
    "for window_size in config.window_sizes:\n",
    "    results = pd.read_csv('out/results/{}_{}_pred_results_windowsize_{}.csv'.format(\n",
    "                config.classifier_type, config.clf_mode, window_size), index_col=0, usecols=lambda x: x not in ['fit_time', 'score_time'])\n",
    "    score = results.loc[subject_ids, metrics]\n",
    "    scores.append(score)\n",
    "scores = np.array(scores)\n",
    "for i in range(scores.shape[2]):\n",
    "    fig, axes = putil.create_plot(nrows=1, ncols=1, sharey=True)\n",
    "    for ax in axes:\n",
    "        putil.set_ax_visible_spines(ax, top=False, right=False)\n",
    "    putil.set_figure_size(fig, 5, 5)\n",
    "    axes[0].boxplot(np.transpose(scores[:, :, i]))\n",
    "    putil.set_ax_xticks(axes[0], range(1, scores.shape[0]+1), config.window_sizes)\n",
    "    putil.set_ax_yticks(axes[0], np.linspace(0.5, 1, 5), np.linspace(0.5, 1, 5))\n",
    "    putil.set_ax_axis_labels(axes[0], x_label='window sizes [s]', y_label=[s.replace('_', ' ').replace('roc auc', 'AUROC') for s in metrics][i])\n",
    "    putil.set_ax_bg_color(axes[0], 'whitesmoke')\n",
    "    putil.set_ax_grid_lines(axes[0], True, axis=\"y\", color=\"w\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('out/results/{}_{}_scores_varying_window_sizes_{}.pdf'.format(config.classifier_type, config.clf_mode, metrics[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare signal combos\n",
    "mean_scores = []\n",
    "stddevs = []\n",
    "window_size = 60\n",
    "for combo in SIGNAL_COMBOS:\n",
    "    signal_string = ''\n",
    "    for signal in combo:\n",
    "        signal_string += '_' + signal\n",
    "    results = pd.read_csv('out/results/{}_{}_pred_results_windowsize_{}{}.csv'.format(\n",
    "                config.classifier_type, config.clf_mode, window_size, signal_string), index_col=0, usecols=lambda x: x not in ['fit_time', 'score_time'])\n",
    "    mean_score = results.loc[subject_ids, scores]\n",
    "    stddev = results.loc['stddev', scores]\n",
    "    mean_scores.append(mean_score)\n",
    "    stddevs.append(stddev)\n",
    "mean_scores = np.array(mean_scores)\n",
    "stddevs = np.array(stddevs)\n",
    "for i in range(mean_scores.shape[1]):\n",
    "    axes[1].plot(range(len(mean_scores)), mean_scores[:, i], markerfacecolor='white', marker=\"o\", label=scores[i])\n",
    "    axes[1].fill_between(range(len(mean_scores)), y1=mean_scores[:, i]-stddevs[:, i], y2=mean_scores[:, i]+stddevs[:, i], alpha=0.2)\n",
    "putil.set_ax_xticks(axes[1], range(len(mean_scores)), SIGNAL_COMBOS, rotation=90)\n",
    "putil.set_ax_axis_labels(axes[1], 'signal combos')\n",
    "putil.set_ax_bg_color(axes[1], 'whitesmoke')\n",
    "putil.set_ax_grid_lines(axes[1], True, axis=\"y\", color=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare step sizes\n",
    "scores = []\n",
    "window_size = 120\n",
    "for step_size in config.step_sizes:\n",
    "    step = 1\n",
    "    if step_size is not None:\n",
    "        results = pd.read_csv('out/results/{}_{}_pred_results_step_size_{}_windowsize_{}.csv'.format(\n",
    "                    config.classifier_type, config.clf_mode, step_size, window_size), index_col=0, usecols=lambda x: x not in ['fit_time', 'score_time'])\n",
    "        score = results.loc[subject_ids, metrics]\n",
    "        scores.append(score)\n",
    "scores = np.array(scores)\n",
    "for i in range(scores.shape[2]):\n",
    "    fig, axes = putil.create_plot(nrows=1, ncols=1, sharey=True)\n",
    "    for ax in axes:\n",
    "        putil.set_ax_visible_spines(ax, top=False, right=False)\n",
    "    putil.set_figure_size(fig, 5, 5)\n",
    "    axes[0].boxplot(np.transpose(scores[:, :, i]))\n",
    "    putil.set_ax_xticks(axes[0], range(1, scores.shape[0]+1), config.step_sizes)\n",
    "    putil.set_ax_yticks(axes[0], np.linspace(0.5, 1, 5), np.linspace(0.5, 1, 5))\n",
    "    putil.set_ax_axis_labels(axes[0], x_label='step sizes [s]', y_label=[s.replace('_', ' ').replace('roc auc', 'AUROC') for s in metrics][i])\n",
    "    putil.set_ax_bg_color(axes[0], 'whitesmoke')\n",
    "    putil.set_ax_grid_lines(axes[0], True, axis=\"y\", color=\"w\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('out/results/{}_{}_scores_varying_step_sizes_{}.pdf'.format(config.classifier_type, config.clf_mode, metrics[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotting_util as putil\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "SIGNAL_COMBOS = [['driver_behavior', 'vehicle_behavior'], ['driver_behavior', 'vehicle_behavior', 'navi'],\n",
    "                ['driver_behavior', 'vehicle_behavior', 'radar'], ['driver_behavior', 'vehicle_behavior', 'navi', 'radar']]\n",
    "\n",
    "SCENARIOS = ['highway', 'rural', 'town']\n",
    "\n",
    "colors = ['blue', 'royalblue', 'green', 'limegreen']\n",
    "\n",
    "# compare scenarios\n",
    "for i, window_size in enumerate(config.window_sizes):\n",
    "    for j, combo in enumerate(SIGNAL_COMBOS):\n",
    "        scores = []\n",
    "        signal_string = ''\n",
    "        for signal in combo:\n",
    "            signal_string += '_' + signal\n",
    "        for k, scenario in enumerate(SCENARIOS):\n",
    "            results = pd.read_csv('out/results/{}_{}_pred_results_windowsize_{}{}_{}.csv'.format(\n",
    "                            config.classifier_type, config.clf_mode, window_size, signal_string, scenario), index_col=0, usecols=lambda x: x not in ['fit_time', 'score_time'])\n",
    "            scores.append(results.loc[subject_ids, metrics])\n",
    "        scores = np.array(scores)\n",
    "        for l in range(scores.shape[2]):\n",
    "            fig, axes = putil.create_plot()\n",
    "            putil.set_ax_visible_spines(axes[0], top=False, right=False)\n",
    "            putil.set_figure_size(fig, 5, 5)\n",
    "            axes[0].boxplot(np.transpose(scores[:, :, l]))\n",
    "            putil.set_ax_title(axes[0], combo)\n",
    "            putil.set_ax_xticks(axes[0], range(1, len(SCENARIOS)+1), SCENARIOS)\n",
    "            putil.set_ax_axis_labels(axes[0], x_label='scenarios', y_label=metrics[l].replace('_', ' ').replace('roc auc', 'ROC AUC'))\n",
    "            putil.set_ax_bg_color(axes[0], 'whitesmoke')\n",
    "            putil.set_ax_grid_lines(axes[0], True, axis=\"y\", color=\"w\")\n",
    "            #putil.set_fig_title(fig, title='Scores per scenario (window size: {}s)'.format(window_size), font_size=14, font_weight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('out/results/{}_{}_{}_scores_per_scenario{}_{}.pdf'.format(config.classifier_type, config.dataset, config.clf_mode, signal_string, metrics[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotting_util as putil\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "EVENTS = ['brake', 'brake_to_gas', 'gas', 'gas_to_brake', 'overtaking', 'road_sign', 'turning']\n",
    "\n",
    "SCENARIOS = ['highway', 'rural', 'town']\n",
    "\n",
    "scores = []\n",
    "for scenario in SCENARIOS:\n",
    "    results = pd.read_csv('out/results/{}_{}_pred_results_combined_events_{}.csv'.format(\n",
    "                config.classifier_type, config.clf_mode, scenario), index_col=0, usecols=lambda x: x not in ['fit_time', 'score_time'])\n",
    "    scores.append(results.loc[subject_ids, metrics])\n",
    "scores = np.array(scores)\n",
    "for i in range(scores.shape[2]):\n",
    "    fig, axes = putil.create_plot()\n",
    "    putil.set_ax_visible_spines(axes[0], top=False, right=False)\n",
    "    putil.set_figure_size(fig, 5, 5)\n",
    "    axes[0].boxplot(np.transpose(scores[:, :, l]))\n",
    "    putil.set_ax_xticks(axes[0], range(1, len(SCENARIOS)+1), SCENARIOS)\n",
    "    putil.set_ax_axis_labels(axes[0], x_label='scenarios', y_label=metrics[i].replace('_', ' ').replace('roc auc', 'ROC AUC'))\n",
    "    putil.set_ax_bg_color(axes[0], 'whitesmoke')\n",
    "    putil.set_ax_grid_lines(axes[0], True, axis=\"y\", color=\"w\")\n",
    "    #putil.set_fig_title(fig, title='Scores for all events combined', font_size=14, font_weight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('out/results/{}_{}_scores_events_combined_{}.pdf'.format(config.classifier_type, config.clf_mode, metrics[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotting_util as putil\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "EVENTS = ['brake', 'brake_to_gas', 'gas', 'gas_to_brake', 'overtaking', 'road_sign', 'turning']\n",
    "\n",
    "SCENARIOS = ['highway', 'rural', 'town']\n",
    "\n",
    "for i, event in enumerate(EVENTS):\n",
    "    scores = []\n",
    "    for scenario in SCENARIOS:\n",
    "        if event == 'turning' and scenario == 'highway':\n",
    "            continue\n",
    "        else:\n",
    "            results = pd.read_csv('out/results/{}_{}_pred_results_{}_{}.csv'.format(\n",
    "                        config.classifier_type, config.clf_mode, event, scenario), index_col=0, usecols=lambda x: x not in ['fit_time', 'score_time'])\n",
    "            scores.append(results.loc[subject_ids, metrics])\n",
    "    scores = np.array(scores)\n",
    "    for j in range(scores.shape[2]):\n",
    "        fig, axes = putil.create_plot()\n",
    "        putil.set_ax_visible_spines(axes[0], top=False, right=False)\n",
    "        putil.set_figure_size(fig, 5, 5)\n",
    "        axes[0].boxplot(np.transpose(scores[:, :, j]))\n",
    "        putil.set_ax_xticks(axes[0], range(1, len(SCENARIOS)+1), SCENARIOS)\n",
    "        putil.set_ax_title(axes[0], event + ' events')\n",
    "        putil.set_ax_bg_color(axes[0], 'whitesmoke')\n",
    "        putil.set_ax_grid_lines(axes[0], True, axis=\"y\", color=\"w\")\n",
    "        putil.set_ax_axis_labels(axes[0], x_label='scenarios', y_label=metrics[j].replace('_', ' ').replace('roc auc', 'ROC AUC'))\n",
    "        #putil.set_fig_title(fig, title='Scores per event', font_size=14, font_weight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('out/results/{}_{}_scores_per_event_{}.pdf'.format(config.classifier_type, config.clf_mode, metrics[j]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb6cecb4b017aacc75af7fc465a2b65ff55fcf20de66591fd1094dae1cba1d54"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('DRIVE-venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
